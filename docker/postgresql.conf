# PostgreSQL Configuration for MAAS Workloads
# Optimized for TrueNAS deployment
# Version: PostgreSQL 15
# Target: MAAS Region Controller Database

# =============================================================================
# CONNECTIONS AND AUTHENTICATION
# =============================================================================

# Listen on all interfaces (required for Docker port mapping)
# When using Docker with port mapping, PostgreSQL must listen on all interfaces
# to accept connections from the host or other containers
listen_addresses = '*'

# Maximum number of concurrent connections
# MAAS typically needs 20-50 connections depending on scale
# Set higher for larger deployments (500+ nodes)
max_connections = 100

# Superuser reserved connections
superuser_reserved_connections = 3

# =============================================================================
# MEMORY CONFIGURATION
# =============================================================================

# Shared memory buffer
# Set to 25% of available RAM for dedicated PostgreSQL server
# For TrueNAS with 8GB RAM: 2GB
# For TrueNAS with 16GB RAM: 4GB
# For TrueNAS with 32GB+ RAM: 8GB
shared_buffers = 2GB

# Effective cache size
# Set to 50-75% of available RAM
# This tells PostgreSQL how much memory is available for disk caching
# For 8GB RAM: 6GB
# For 16GB RAM: 12GB
# For 32GB+ RAM: 24GB
effective_cache_size = 6GB

# Memory for complex operations (sorts, joins, hash tables)
# Increase for MAAS queries with large result sets
# Formula: (shared_buffers / max_connections) but at least 4MB
work_mem = 20MB

# Memory for maintenance operations (VACUUM, CREATE INDEX)
# Set to 5-10% of RAM
maintenance_work_mem = 512MB

# =============================================================================
# WRITE AHEAD LOG (WAL)
# =============================================================================

# WAL buffer size
# Larger values improve write performance for busy systems
wal_buffers = 16MB

# Minimum WAL size
# Prevents excessive checkpoint activity
min_wal_size = 1GB

# Maximum WAL size
# Allows PostgreSQL to spread out checkpoint I/O
max_wal_size = 4GB

# WAL level for replication (if needed for HA)
wal_level = replica

# Compression for WAL
wal_compression = on

# =============================================================================
# CHECKPOINTS
# =============================================================================

# Checkpoint timeout
# Time between automatic checkpoints
checkpoint_timeout = 15min

# Checkpoint completion target
# Spread checkpoint I/O over this fraction of checkpoint interval
checkpoint_completion_target = 0.9

# =============================================================================
# QUERY PLANNER
# =============================================================================

# Random page cost
# Lower values favor index scans over sequential scans
# Use 1.1 for SSD storage, 4.0 for HDD
# TrueNAS typically uses SSDs or enterprise storage
random_page_cost = 1.1

# Effective I/O concurrency
# Number of concurrent disk I/O operations
# Set to number of separate drives in RAID or SSD queue depth
# For NVMe SSD: 200, for SATA SSD: 50, for HDD RAID: 10
effective_io_concurrency = 200

# =============================================================================
# LOGGING
# =============================================================================

# Log destination
logging_collector = on
log_directory = '/var/lib/postgresql/data/log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'

# Log rotation
log_rotation_age = 1d
log_rotation_size = 100MB

# What to log
log_min_duration_statement = 1000  # Log queries taking more than 1 second
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_lock_waits = on
log_temp_files = 0  # Log all temp file usage
log_autovacuum_min_duration = 0  # Log all autovacuum activity

# =============================================================================
# AUTOVACUUM
# =============================================================================

# Enable autovacuum (critical for MAAS)
autovacuum = on

# Maximum number of autovacuum processes
# Increase for larger databases
autovacuum_max_workers = 3

# Naptime between autovacuum runs
autovacuum_naptime = 1min

# Vacuum cost delay (throttling)
# Set to 0 for fastest vacuuming (may impact query performance)
autovacuum_vacuum_cost_delay = 10ms

# Vacuum cost limit
# Higher values make vacuum more aggressive
autovacuum_vacuum_cost_limit = 200

# Threshold for triggering vacuum
# Lower values make vacuum more aggressive
autovacuum_vacuum_threshold = 50
autovacuum_vacuum_scale_factor = 0.1

# Threshold for triggering analyze
autovacuum_analyze_threshold = 50
autovacuum_analyze_scale_factor = 0.05

# =============================================================================
# STATISTICS
# =============================================================================

# Track activity and statistics
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all

# Statistics targets
# Higher values improve query planning accuracy but increase ANALYZE time
default_statistics_target = 100

# =============================================================================
# CLIENT CONNECTION DEFAULTS
# =============================================================================

# Timezone
timezone = 'Etc/UTC'

# Locale settings
lc_messages = 'C'
lc_monetary = 'C'
lc_numeric = 'C'
lc_time = 'C'

# Character set
client_encoding = 'UTF8'

# Text search configuration
default_text_search_config = 'pg_catalog.english'

# =============================================================================
# LOCK MANAGEMENT
# =============================================================================

# Maximum number of locks per transaction
# MAAS may need more locks for complex operations
max_locks_per_transaction = 64

# Maximum number of predicate locks per transaction
max_pred_locks_per_transaction = 64

# =============================================================================
# ERROR HANDLING
# =============================================================================

# Restart after backend crash
restart_after_crash = on

# =============================================================================
# PERFORMANCE TUNING FOR MAAS SPECIFIC OPERATIONS
# =============================================================================

# Parallel query execution
# Enable for large deployments (1000+ nodes)
max_parallel_workers_per_gather = 2
max_parallel_workers = 4
max_worker_processes = 4

# Statement timeout (0 = disabled)
# Consider enabling for production to prevent runaway queries
# statement_timeout = 30000  # 30 seconds

# Idle in transaction timeout
# Terminate idle transactions after this duration
idle_in_transaction_session_timeout = 300000  # 5 minutes

# =============================================================================
# SECURITY
# =============================================================================

# SSL/TLS (configure if needed)
# ssl = off  # Set to 'on' and configure certificates in production

# Password encryption
password_encryption = scram-sha-256

# =============================================================================
# NOTES
# =============================================================================

# This configuration is optimized for:
# - MAAS region controller database workload
# - Systems with 8GB+ RAM
# - SSD or enterprise storage
# - 100-1000 managed nodes
#
# Adjust the following based on your deployment:
# 1. shared_buffers: 25% of available RAM
# 2. effective_cache_size: 50-75% of available RAM
# 3. work_mem: shared_buffers / max_connections
# 4. max_connections: Based on MAAS scale (20-50 typical, 100+ for large)
# 5. random_page_cost: 1.1 for SSD, 4.0 for HDD
# 6. effective_io_concurrency: Based on storage type
#
# For systems with different RAM:
# - 4GB RAM: shared_buffers=1GB, effective_cache_size=3GB
# - 8GB RAM: shared_buffers=2GB, effective_cache_size=6GB
# - 16GB RAM: shared_buffers=4GB, effective_cache_size=12GB
# - 32GB+ RAM: shared_buffers=8GB, effective_cache_size=24GB
#
# Monitor and adjust based on:
# - pg_stat_statements
# - EXPLAIN ANALYZE output
# - System metrics (CPU, RAM, I/O)
# - PostgreSQL logs
#
# Testing and benchmarking tools:
# - pgbench: Built-in PostgreSQL benchmarking
# - pg_stat_statements: Query performance tracking
# - EXPLAIN ANALYZE: Query execution analysis
